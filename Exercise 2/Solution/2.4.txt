We noted that, for  AlexNet architecture, training accuracy does not go beyond 80% even after applying augmentation. Also loss is not decresed anymore by training for more number of epochs. This suggests our model is underfitting. The reason for underfitting is Alexnet architecture is too simple. i.e. it has only 5 convolution layers and 3 Max pooling layers which do not seem enough to capture features of "Dog Breed" dataset.
