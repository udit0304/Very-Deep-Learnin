{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "#print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import dataset\n",
    "from torch.utils.data import  DataLoader\n",
    "from AlexNet import AlexNet\n",
    "from train_test import start_train_test\n",
    "from torchvision import  models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Preparing DOG-BREED dataset...\n",
      "Output classes: 120\n",
      "Input channels: 3\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, outputs, inputs = dataset('dog-breed')\n",
    "print ('Output classes: {}\\nInput channels: {}'.format(outputs, inputs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Code \n",
    "net = AlexNet(num_classes = outputs,inputs=inputs)\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loss, test_loss = start_train_test(net, trainloader, testloader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): AlexNet(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "      (1): ReLU(inplace)\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (4): ReLU(inplace)\n",
      "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU(inplace)\n",
      "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (9): ReLU(inplace)\n",
      "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace)\n",
      "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.5)\n",
      "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Dropout(p=0.5)\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU(inplace)\n",
      "      (fc): Linear(in_features=4096, out_features=120, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Transfer Learning Code\n",
    "\n",
    "#net = AlexNet(num_classes = outputs,inputs=inputs)\n",
    "from torchsummary import summary\n",
    "file_name = 'alexnet-'\n",
    "#import pretrainedmodels \n",
    "alexnet = models.alexnet(pretrained='imagenet')\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "new_classifier = nn.Sequential(*list(alexnet.classifier.children())[:-1])\n",
    "new_classifier.fc = nn.Linear(4096, 120)\n",
    "alexnet.classifier = new_classifier\n",
    "alexnet.cuda()\n",
    "alexnet = torch.nn.DataParallel(alexnet,device_ids = range(torch.cuda.device_count()))\n",
    "cudnn.benchmark = True\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if use_cuda:\n",
    " #net.cuda()\n",
    " #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "#cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#torch.save(net.sate_dict(),\"/home/pkhan/Code/Very-Deep-Learnin/Exercise 2/data/dog-breed/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Training Epoch #1, LR=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pkhan/Code/Very-Deep-Learnin/Exercise 2/train_test.py:33: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  train_loss += loss.data[0]\n",
      "/home/pkhan/Code/Very-Deep-Learnin/Exercise 2/train_test.py:37: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  train_loss_stacked = np.append(train_loss_stacked, loss.data[0].cpu().numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [  1/150] \t\tLoss: 1.7785 Acc@1: 41.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pkhan/Code/Very-Deep-Learnin/Exercise 2/train_test.py:39: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  %(epoch, cf.num_epochs, loss.data[0], 100.*correct/total))\n",
      "/home/pkhan/Code/Very-Deep-Learnin/Exercise 2/train_test.py:59: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  test_loss += loss.data[0]\n",
      "/home/pkhan/Code/Very-Deep-Learnin/Exercise 2/train_test.py:63: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  test_loss_stacked = np.append(test_loss_stacked, loss.data[0].cpu().numpy())\n",
      "/home/pkhan/Code/Very-Deep-Learnin/Exercise 2/train_test.py:68: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" % (epoch, loss.data[0], acc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Validation Epoch #1\t\t\tLoss: 0.7169 Acc@1: 76.00%\n",
      "* Test results : Acc@1 = 76.00%\n",
      "| Elapsed time : 0:00:44\n",
      "\n",
      "=> Training Epoch #2, LR=0.0010\n",
      "| Epoch [  2/150] \t\tLoss: 1.0355 Acc@1: 62.000%\n",
      "\n",
      "| Validation Epoch #2\t\t\tLoss: 0.5084 Acc@1: 83.00%\n",
      "* Test results : Acc@1 = 83.00%\n",
      "| Elapsed time : 0:01:30\n",
      "\n",
      "=> Training Epoch #3, LR=0.0010\n",
      "| Epoch [  3/150] \t\tLoss: 1.1333 Acc@1: 70.000%\n",
      "\n",
      "| Validation Epoch #3\t\t\tLoss: 0.3411 Acc@1: 89.00%\n",
      "* Test results : Acc@1 = 89.00%\n",
      "| Elapsed time : 0:02:15\n",
      "\n",
      "=> Training Epoch #4, LR=0.0010\n",
      "| Epoch [  4/150] \t\tLoss: 0.8096 Acc@1: 75.000%\n",
      "\n",
      "| Validation Epoch #4\t\t\tLoss: 0.2788 Acc@1: 91.00%\n",
      "* Test results : Acc@1 = 91.00%\n",
      "| Elapsed time : 0:02:59\n",
      "\n",
      "=> Training Epoch #5, LR=0.0010\n",
      "| Epoch [  5/150] \t\tLoss: 0.8195 Acc@1: 77.000%\n",
      "\n",
      "| Validation Epoch #5\t\t\tLoss: 0.1631 Acc@1: 95.00%\n",
      "* Test results : Acc@1 = 95.00%\n",
      "| Elapsed time : 0:03:43\n",
      "\n",
      "=> Training Epoch #6, LR=0.0010\n",
      "| Epoch [  6/150] \t\tLoss: 0.6203 Acc@1: 80.000%\n",
      "\n",
      "| Validation Epoch #6\t\t\tLoss: 0.1437 Acc@1: 94.00%\n",
      "* Test results : Acc@1 = 95.00%\n",
      "| Elapsed time : 0:04:26\n",
      "\n",
      "=> Training Epoch #7, LR=0.0010\n",
      "| Epoch [  7/150] \t\tLoss: 0.6770 Acc@1: 82.000%\n",
      "\n",
      "| Validation Epoch #7\t\t\tLoss: 0.1618 Acc@1: 96.00%\n",
      "* Test results : Acc@1 = 96.00%\n",
      "| Elapsed time : 0:05:11\n",
      "\n",
      "=> Training Epoch #8, LR=0.0010\n",
      "| Epoch [  8/150] \t\tLoss: 0.7458 Acc@1: 83.000%\n",
      "\n",
      "| Validation Epoch #8\t\t\tLoss: 0.1114 Acc@1: 97.00%\n",
      "* Test results : Acc@1 = 97.00%\n",
      "| Elapsed time : 0:05:56\n",
      "\n",
      "=> Training Epoch #9, LR=0.0010\n",
      "| Epoch [  9/150] \t\tLoss: 0.5737 Acc@1: 84.000%\n",
      "\n",
      "| Validation Epoch #9\t\t\tLoss: 0.1328 Acc@1: 97.00%\n",
      "* Test results : Acc@1 = 97.00%\n",
      "| Elapsed time : 0:06:41\n",
      "\n",
      "=> Training Epoch #10, LR=0.0010\n",
      "| Epoch [ 10/150] \t\tLoss: 0.4808 Acc@1: 85.000%\n",
      "\n",
      "| Validation Epoch #10\t\t\tLoss: 0.1169 Acc@1: 97.00%\n",
      "* Test results : Acc@1 = 97.00%\n",
      "| Elapsed time : 0:07:32\n",
      "\n",
      "=> Training Epoch #11, LR=0.0010\n",
      "| Epoch [ 11/150] \t\tLoss: 0.4453 Acc@1: 86.000%\n",
      "\n",
      "| Validation Epoch #11\t\t\tLoss: 0.0642 Acc@1: 97.00%\n",
      "* Test results : Acc@1 = 97.00%\n",
      "| Elapsed time : 0:08:21\n",
      "\n",
      "=> Training Epoch #12, LR=0.0010\n",
      "| Epoch [ 12/150] \t\tLoss: 0.4884 Acc@1: 85.000%\n",
      "\n",
      "| Validation Epoch #12\t\t\tLoss: 0.0788 Acc@1: 97.00%\n",
      "* Test results : Acc@1 = 97.00%\n",
      "| Elapsed time : 0:09:10\n",
      "\n",
      "=> Training Epoch #13, LR=0.0010\n",
      "| Epoch [ 13/150] \t\tLoss: 0.3416 Acc@1: 87.000%\n",
      "\n",
      "| Validation Epoch #13\t\t\tLoss: 0.0913 Acc@1: 97.00%\n",
      "* Test results : Acc@1 = 97.00%\n",
      "| Elapsed time : 0:09:55\n",
      "\n",
      "=> Training Epoch #14, LR=0.0010\n",
      "| Epoch [ 14/150] \t\tLoss: 0.6190 Acc@1: 86.000%\n",
      "\n",
      "| Validation Epoch #14\t\t\tLoss: 0.0809 Acc@1: 97.00%\n",
      "* Test results : Acc@1 = 97.00%\n",
      "| Elapsed time : 0:10:42\n",
      "\n",
      "=> Training Epoch #15, LR=0.0010\n",
      "| Epoch [ 15/150] \t\tLoss: 0.2945 Acc@1: 87.000%\n",
      "\n",
      "| Validation Epoch #15\t\t\tLoss: 0.1356 Acc@1: 98.00%\n",
      "* Test results : Acc@1 = 98.00%\n",
      "| Elapsed time : 0:11:41\n",
      "\n",
      "=> Training Epoch #16, LR=0.0010\n",
      "| Epoch [ 16/150] \t\tLoss: 0.5149 Acc@1: 86.000%\n",
      "\n",
      "| Validation Epoch #16\t\t\tLoss: 0.1455 Acc@1: 97.00%\n",
      "* Test results : Acc@1 = 98.00%\n",
      "| Elapsed time : 0:12:32\n",
      "\n",
      "=> Training Epoch #17, LR=0.0010\n",
      "| Epoch [ 17/150] \t\tLoss: 0.4890 Acc@1: 87.000%\n",
      "\n",
      "| Validation Epoch #17\t\t\tLoss: 0.0821 Acc@1: 98.00%\n",
      "* Test results : Acc@1 = 98.00%\n",
      "| Elapsed time : 0:13:18\n",
      "\n",
      "=> Training Epoch #18, LR=0.0010\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/pkhan/Code/Very-Deep-Learnin/Exercise 2/util.py\", line 30, in __getitem__\n    with Image.open(img_name) as f:\n  File \"/usr/lib64/python3.6/site-packages/PIL/Image.py\", line 2609, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: './data/dog-breed/train/36b6be29fc246ceb52d58ab01584773e.jpg'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4d66da3a128a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malexnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/Very-Deep-Learnin/Exercise 2/train_test.py\u001b[0m in \u001b[0;36mstart_train_test\u001b[0;34m(net, trainloader, testloader, criterion)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Very-Deep-Learnin/Exercise 2/train_test.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, net, trainloader, criterion)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n=> Training Epoch #%d, LR=%.4f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(inputs_value.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/pkhan/Code/Very-Deep-Learnin/Exercise 2/util.py\", line 30, in __getitem__\n    with Image.open(img_name) as f:\n  File \"/usr/lib64/python3.6/site-packages/PIL/Image.py\", line 2609, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: './data/dog-breed/train/36b6be29fc246ceb52d58ab01584773e.jpg'\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss = start_train_test(alexnet, trainloader, testloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(train_loss)\n",
    "plt.ylabel('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_loss)\n",
    "plt.ylabel('Test Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Predict import test\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "test(net)\n",
    "\n",
    "#print(top_probs)\n",
    "\n",
    "#print(top_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
